---
title: "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation"
date: 2025-06-13 18:00:00 +0900
categories:
  - Paper-Review
  - Uncertainty Estimation
tags:
  - Uncertainty Estimation
  - Semantic Uncertainty
  - ICLR 2023

description: 
toc: true
comments: false
cdn: 
image:
math: true
pin: false
mermaid: false
---

## 📄 논문 정보
[**"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation" (ICLR 2023)**](https://arxiv.org/abs/2302.09664)

## 🔍 연구 배경 및 문제의식
AI라는 개념이 우리에게 본격적으로 다가온 것은 아마도 알파고의 등장이 계기였을 것이다. 불과 몇 년 전만 해도 멀게만 느껴졌던 기술이 이제는 ChatGPT나 Gemini와 같은 언어 모델의 형태로 우리의 일상 속 깊숙이 자리 잡고 있다. 우리는 자연스럽게 AI에게 질문을 던지고, 복잡한 글쓰기를 부탁하며, 때로는 번역이나 요약까지도 맡긴다. 이처럼 자연어 생성(Natural Language Generation, NLG)이 널리 활용되면서, 한 가지 중요한 질문이 떠오른다. **“언어 모델이 내놓는 대답을 우리는 얼마나 신뢰할 수 있는가?”** 단지 문장을 생성했다는 이유만으로 그 답이 옳다고 보아도 될까? 혹은 표현이 익숙하지 않다면, 그것은 틀린 답변일까?

기존의 딥러닝 모델들은 이미지 분류나 숫자 예측처럼 명확한 정답이 있는 문제에서 예측의 신뢰도를 확률 분포나 엔트로피를 통해 정량적으로 측정해왔다. 하지만 자연어는 다르다. 하나의 질문에 대해 동일한 의미를 가진 다양한 표현들이 존재할 수 있기 때문이다. 같은 의미를 여러 방식으로 표현할 수 있는 언어의 특성은, 기존의 확률 기반 불확실성 측정 방식으로는 포착되기 어렵다.

예컨대 언어 모델이 같은 질문에 대해 “파리입니다” 또는 “프랑스의 수도는 파리예요”라고 답할 수 있다. 사람은 이 두 문장이 동일한 의미를 갖는다는 것을 쉽게 이해하지만, 기존의 언어 모델은 표현의 차이를 근거로 서로 다른 결과로 간주하고, 불필요하게 높은 불확실성을 계산해낸다. 이는 결국 모델의 신뢰도를 왜곡시키고, 실제보다 불안정해 보이게 만들 수 있다.

이 논문은 이러한 문제의식에서 출발한다. 저자들은 자연어의 본질인 “의미”에 주목하여, 문장 단위가 아닌 의미 단위로 확률을 재구성하는 새로운 불확실성 지표인 Semantic Entropy를 제안한다. 핵심 아이디어는 단순하다. 같은 의미를 가진 표현은 하나로 묶고, 그 집합에 대해 엔트로피를 계산하자. 이를 통해 모델이 실제로 얼마나 다양한 의미를 동시에 고려하고 있는지를 보다 정확히 파악할 수 있다.

무엇보다도 이 방법은 비지도 방식으로 동작하며, 별도의 추가 학습이나 모델 구조 변경 없이도 기존의 대형 언어 모델에 그대로 적용 가능하다는 점에서 실용성과 확장성이 높다. 본 연구는 이러한 Semantic Entropy 개념을 이론적으로 정립하고, 다양한 자연어 질문응답 데이터셋에서 기존 방법들과의 비교 실험을 통해 그 효과를 실증적으로 보여준다.

## 기존 불확실성 측정의 한계

그렇다면 우선, 기존의 언어 모델들은 **불확실성(uncertainty)**을 어떤 방식으로 측정해왔을까?

기존 딥러닝에서는 출력에 대한 확신의 정도를 **예측 분포의 엔트로피(entropy)**로 측정한다. 예를 들어, 입력 $$x$$에 대해 출력 $$y$$가 나올 확률 분포가 $$p(y \mid x)$$라고 할 때, 이 분포의 엔트로피는 다음과 같이 정의된다.

$$
H(Y \mid x) = - \int p(y \mid x) \log p(y \mid x) \, dy
$$

이 값이 높을수록 모델은 불확실하며, 낮을수록 확신을 가지고 있는 것으로 해석된다.

자연어 생성의 경우, 하나의 출력 문장 
$$
s = (s_1, s_2, \dots, s_n)
$$
는 토큰 단위의 조건부 확률로 계산된다. 즉, 문장 전체의 확률은 다음과 같다.

$$
p(s \mid x) = \prod_{i=1}^{n} p(s_i \mid s_{<i}, x)
$$

따라서 로그 확률은 다음과 같이 계산되며,

$$
\log p(s \mid x) = \sum_{i=1}^{n} \log p(s_i \mid s_{<i}, x)
$$

이를 통해 전체 문장의 확률 또는 로그 확률을 기반으로 불확실성을 추정한다. 다만, 문장이 길어질수록 곱셈된 확률이 작아지는 문제가 있어, 이를 보완하기 위해 문장 길이로 정규화한 로그 확률도 자주 사용된다.

$$
\frac{1}{n} \sum_{i=1}^{n} \log p(s_i \mid s_{<i}, x)
$$

이러한 방식은 단어 수가 많은 문장에 불리하게 작용하는 것을 막고, 문장 간의 확률 비교를 보다 공정하게 만든다. 하지만 이런 방식들은 모두 문장 단위의 토큰 시퀀스를 별개로 간주한다는 점에서 한계가 있다. 의미적으로 동일한 문장이라 하더라도 표현이 다르면 서로 다른 확률 항목으로 처리되어, 실제보다 더 높은 불확실성이 계산된다. 자연어에서 같은 의미를 가진 다양한 표현이 가능하다는 점을 고려하면, 이는 근본적인 한계이며 불확실성 측정을 왜곡시킬 수 있다.

더불어 자연어 생성의 출력 공간은 
$$
O(|T|^N)
$$
에 달할 정도로 **고차원적**이기 때문에, 전체 엔트로피를 계산하기 위해 **몬테카를로 샘플링**에 의존할 수밖에 없다. 그러나 이 경우 **확률이 낮은 문장들(low-probability sequences)**이 로그 값에 의해 엔트로피에 과도하게 기여하게 되며, 샘플 수가 부족할 경우 **엔트로피 추정이 불안정**해진다는 문제가 있다.

게다가 자연어 응답은 길이가 제각각이기 때문에, 길이에 따른 로그 확률의 감소로 인해 긴 문장이 무조건 더 불확실하다고 평가되는 **길이 편향(length bias)** 문제도 존재한다. 이를 막기 위해 길이 정규화된 엔트로피가 제안되긴 했지만, 항상 이상적인 해법은 아니다. 예컨대 정답이 짧은 경우(예: TriviaQA)에는 유효할 수 있지만, 다양한 길이의 정답이 존재하는 경우(CoQA 등)에는 오히려 왜곡을 초래할 수 있다.

이처럼 기존의 불확실성 측정 방식은 **표현의 다양성과 문장의 구조적 특성**을 충분히 반영하지 못하며, 특히 **같은 의미를 가진 다양한 표현들에 대해 인위적으로 높은 불확실성**을 부여하는 문제가 있다.

👉 본 논문은 이러한 한계를 해결하기 위해, **의미 단위(semantic equivalence class)**로 응답을 묶어 불확실성을 계산하는 **Semantic Entropy**를 제안한다. 이 방식은 중복된 표현을 제거하고 실제 의미 간의 다양성에만 주목함으로써, 보다 정교하고 안정적인 불확실성 추정이 가능함을 실험적으로 증명한다.


## 의미 기반 불확실성 측정 (Semantic Entropy)

기존의 불확실성 측정 방식은 언어 모델이 생성한 문장을 각기 독립적인 시퀀스로 간주하여 확률을 계산한다. 하지만 자연어에서는 표현이 달라도 의미가 동일한 문장들이 다수 존재한다. 따라서 문장 자체가 아닌, **문장이 담고 있는 의미(semantic meaning)**를 기준으로 불확실성을 측정해야 한다는 필요성이 제기된다.

이를 위해 저자들은 Semantic Entropy라는 새로운 지표를 제안한다. 핵심 아이디어는 다음과 같다: 언어 모델이 생성한 여러 문장 중에서 같은 의미를 가진 문장들을 하나의 '의미 집합(semantic class)'으로 묶고, 이 의미 단위로 불확실성을 계산한다는 것이다.

구체적으로, 다음과 같은 3단계 절차를 따른다.
1. 샘플링: 주어진 질문이나 문맥 $$𝑥$$ 에 대해 언어 모델로부터 $$𝑀$$ 개의 문장 $$
s^{(1)},\ s^{(2)},\ \dots,\ s^{(M)}
$$을 샘플링한다.
2. 의미 클러스터링: 이들 문장을 서로 의미가 같은 것들끼리 묶는다. 두 문장이 서로를 **양방향으로 함의(entailment)**하면 같은 의미를 가진 것으로 판단한다.
3. 의미 기반 엔트로피 계산: 같은 의미 집합 내의 문장 확률들을 합산하여 의미 단위의 확률 분포를 만들고, 이에 대한 엔트로피를 계산한다.

이 과정을 수식으로 정리하면 다음과 같다. 먼저 의미 집합 $$𝑐 ∈ 𝐶$$ 의 확률은 다음과 같이 정의된다.

$$
p(c \mid x) = \sum_{s \in c} p(s \mid x)
$$

이제 전체 의미 공간 $$C$$에 대해 Semantic Entropy는 다음과 같이 계산된다.

$$
H_{\text{semantic}}(x) = - \sum_{c \in C} p(c \mid x) \log p(c \mid x)
$$

이때 실제 모델이 생성하는 문장들은 전체 의미 공간의 일부만 반영하기 때문에, 위 수식은 샘플링 기반 Monte Carlo 근사로 다음과 같이 표현된다:

$$
H_{\text{semantic}}(x) \approx - \frac{1}{|C|} \sum_{i=1}^{|C|} \log p(C_i \mid x)
$$

이 방식은 표현의 다양성을 허용하면서도 의미의 불확실성만을 측정할 수 있다는 점에서, 기존 방식보다 훨씬 더 직관적이고 신뢰할 수 있는 지표를 제공한다.


### 🎯 예시: 의미 기반 엔트로피 계산

Semantic Entropy가 기존 방식과 어떻게 다른지를 직관적으로 보여주기 위해, 간단한 예시를 통해 비교해보자. 예를 들어, "프랑스의 수도는 어디인가요?"라는 질문에 대해 언어 모델이 다음과 같은 세 문장을 생성했다고 가정하자.

| 문장                                 | 확률 \( p(s $$\mid$$ x) \) |
|--------------------------------------|:-----------------------:|
| A: "파리입니다."                      |           0.5           |
| B: "프랑스의 수도는 파리예요."         |           0.4           |
| C: "런던입니다."                      |           0.1           |

기존의 엔트로피 계산 방식은 이 세 문장을 모두 독립적으로 처리하여 다음과 같은 엔트로피를 계산한다.

$$H = - (0.5 * log 0.5 + 0.4 * log 0.4 + 0.1 * log 0.1) ≈ 0.94$$

이 값은 모델이 상당한 불확실성을 갖는 것으로 해석된다. 그러나 A와 B는 의미적으로 동일한 문장이며, 이는 사람이라면 쉽게 인지할 수 있다. 이를 고려해 A와 B를 하나의 의미 집합(semantic class)으로 묶으면, 의미 기반 확률은 다음과 같이 구성된다.

의미 집합 1 (“파리” 관련 답변들): 
- 의미 집합 1 ("파리" 관련): 0.5 + 0.4 = 0.9
- 의미 집합 2 ("런던"): 0.1

이제 의미 단위로 엔트로피를 계산하면:

$$H_semantic = - (0.9 * log 0.9 + 0.1 * log 0.1) ≈ 0.33$$

→ 의미를 기준으로 묶으면 실제 불확실성이 훨씬 낮게 측정됨.

즉, 표면적으로는 다양한 답변이 존재하는 것처럼 보였지만, 의미적 기준으로 보면 대부분의 확률이 하나의 정답에 몰려 있으며, 실제 불확실성은 훨씬 낮다는 것을 알 수 있다.


## 📘 5. 관련 연구 (Related Work)

Semantic Entropy는 기존의 언어 모델 불확실성 추정 연구들과 차별점을 가진다.

- 대부분의 기존 연구는 **분류 또는 회귀 문제에서의 확률 보정(calibration)**에 집중함. 예: Brier score, MC Dropout, Deep Ensembles.
- 그러나 **자연어 생성(NLG)은 의미적 동치(semantic equivalence)** 문제가 존재하여 이러한 방법들이 적합하지 않음.

기존 접근 방식들과 비교:
- **Supervised 방식**: 예측 후에 모델이 “내가 맞았을까?”를 평가하는 방식 (예: p(True), margin probability 등)
  - 문제: task-specific finetuning 필요, OOD에 약함
- **Lexical similarity 기반 방법** (Rouge-L 등)
  - 문제: 의미는 같지만 단어가 다르면 높은 불확실성으로 잘못 평가함

➡ Semantic Entropy는 **unsupervised하고 의미에 기반**하여 기존 한계를 극복한다.

---

### 📗 6. 실험 및 결과 (Empirical Evaluation)

#### 🎯 목표
Semantic Entropy가 기존 불확실성 추정 방법들보다 **더 정확하게 답변의 신뢰도를 추정**할 수 있는지를 평가한다.

#### ⚙️ 실험 세팅

- **모델**: OPT (2.7B, 6.7B, 13B, 30B)
- **데이터셋**:
  - TriviaQA (closed-book QA)
  - CoQA (open-book QA)
- **정답 판별 기준**: Rouge-L 점수가 0.3 이상이면 정답

#### 📊 평가 지표

- **AUROC**: 높은 AUROC일수록 불확실성 추정이 정확
- **기존 방법들과 비교**:
  - Predictive Entropy
  - Length-normalized Entropy
  - p(True)
  - Lexical Similarity

#### ✅ 주요 결과

- Semantic Entropy가 모든 모델 크기에서 기존 방법 대비 높은 AUROC 기록
- 모델이 **틀린 답을 할수록 의미가 다양한 답변 생성 → 높은 semantic entropy**
- 의미 수(클러스터 수)만으로도 꽤 유의미한 불확실성 추정 가능

| Dataset   | 정답일 때 평균 의미 수 | 오답일 때 평균 의미 수 |
|-----------|------------------------|--------------------------|
| CoQA      | 1.27                   | 1.77                     |
| TriviaQA  | 1.89                   | 3.89                     |

---

### 📘 6.2 샘플링 하이퍼파라미터 분석

- **샘플링 temperature**가 semantic entropy에 큰 영향
  - 높은 temperature → 다양성 증가, 정확도 감소
  - 낮은 temperature → 정확도 증가, 다양성 감소
- 가장 높은 AUROC는 **중간 temperature (≈ 0.5)**에서 얻어짐

📌 요점: semantic entropy는 **“다양성 vs 정확도” 간 균형**이 중요

---

### 📙 7. 논의 (Discussion)

Semantic Entropy는 자연어 생성에서 자주 등장하는 **“동일 의미의 다양한 표현” 문제를 정면으로 해결**하려는 시도이다.

- 의미 기반 엔트로피는:
  - 중복 표현의 영향을 줄여 신뢰도 추정 정확도를 향상
  - 모델이 “혼란스러울 때” 다양한 의미를 생성한다는 가정을 잘 포착

#### ✨ 장점

- 기존 LLM에 **학습 없이 적용 가능 (off-the-shelf)**
- 의미 기반이므로 **문장 표현의 다양성에 덜 민감**
- 더 많은 샘플을 사용할수록 성능이 향상

#### ⚠️ 한계 및 향후 과제

- 의미 클러스터링이 **NLI 모델 정확도에 의존** (고온 샘플링에서는 오차 발생)
- 의미 엔트로피 외에도 Mutual Information 기반 방법 등과 결합 가능성 있음
- Summarization과 같이 **정답이 명확하지 않은 생성 과제에는 추가 연구 필요**

