---
title: "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation"
date: 2025-06-13 18:00:00 +0900
categories:
  - Paper-Review
  - Uncertainty Estimation
tags:
  - Uncertainty Estimation
  - Semantic Uncertainty
  - ICLR 2023

description: 
toc: true
comments: false
cdn: 
image:
math: true
pin: false
mermaid: false
---

## 📄 논문 정보
[**"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation" (ICLR 2023)**](https://arxiv.org/abs/2302.09664)

## 🔍 연구 배경 및 문제의식
AI라는 개념이 우리에게 본격적으로 다가온 것은 아마도 알파고의 등장이 계기였을 것이다. 불과 몇 년 전만 해도 멀게만 느껴졌던 기술이 이제는 ChatGPT나 Gemini와 같은 언어 모델의 형태로 우리의 일상 속 깊숙이 자리 잡고 있다. 우리는 자연스럽게 AI에게 질문을 던지고, 복잡한 글쓰기를 부탁하며, 때로는 번역이나 요약까지도 맡긴다. 이처럼 자연어 생성(Natural Language Generation, NLG)이 널리 활용되면서, 한 가지 중요한 질문이 떠오른다. **“언어 모델이 내놓는 대답을 우리는 얼마나 신뢰할 수 있는가?”** 단지 문장을 생성했다는 이유만으로 그 답이 옳다고 보아도 될까? 혹은 표현이 익숙하지 않다면, 그것은 틀린 답변일까?

기존의 딥러닝 모델들은 이미지 분류나 숫자 예측처럼 명확한 정답이 있는 문제에서 예측의 신뢰도를 확률 분포나 엔트로피를 통해 정량적으로 측정해왔다. 하지만 자연어는 다르다. 하나의 질문에 대해 동일한 의미를 가진 다양한 표현들이 존재할 수 있기 때문이다. 같은 의미를 여러 방식으로 표현할 수 있는 언어의 특성은, 기존의 확률 기반 불확실성 측정 방식으로는 포착되기 어렵다.

예컨대 언어 모델이 같은 질문에 대해 “파리입니다” 또는 “프랑스의 수도는 파리예요”라고 답할 수 있다. 사람은 이 두 문장이 동일한 의미를 갖는다는 것을 쉽게 이해하지만, 기존의 언어 모델은 표현의 차이를 근거로 서로 다른 결과로 간주하고, 불필요하게 높은 불확실성을 계산해낸다. 이는 결국 모델의 신뢰도를 왜곡시키고, 실제보다 불안정해 보이게 만들 수 있다.

이 논문은 이러한 문제의식에서 출발한다. 저자들은 자연어의 본질인 “의미”에 주목하여, 문장 단위가 아닌 의미 단위로 확률을 재구성하는 새로운 불확실성 지표인 Semantic Entropy를 제안한다. 핵심 아이디어는 단순하다. 같은 의미를 가진 표현은 하나로 묶고, 그 집합에 대해 엔트로피를 계산하자. 이를 통해 모델이 실제로 얼마나 다양한 의미를 동시에 고려하고 있는지를 보다 정확히 파악할 수 있다.

무엇보다도 이 방법은 비지도 방식으로 동작하며, 별도의 추가 학습이나 모델 구조 변경 없이도 기존의 대형 언어 모델에 그대로 적용 가능하다는 점에서 실용성과 확장성이 높다. 본 연구는 이러한 Semantic Entropy 개념을 이론적으로 정립하고, 다양한 자연어 질문응답 데이터셋에서 기존 방법들과의 비교 실험을 통해 그 효과를 실증적으로 보여준다.

## 기존 불확실성 측정의 한계
그렇다면 우선, 기존의 언어 모델들은 **불확실성(uncertainty)**을 어떤 방식으로 측정해왔을까?

기존 딥러닝에서는 출력에 대한 확신의 정도를 **예측 분포의 엔트로피(entropy)**로 측정한다. 예를 들어, 입력 $$x$$에 대해 출력 $$y$$가 나올 확률 분포가 $$p(y \mid x)$$라고 할 때, 이 분포의 엔트로피는 다음과 같이 정의된다.

$$
H(Y \mid x) = - \int p(y \mid x) \log p(y \mid x) \, dy
$$

이 값이 높을수록 모델은 불확실하며, 낮을수록 확신을 가지고 있는 것으로 해석된다.

자연어 생성의 경우, 하나의 출력 문장 $$
s = (s_1, s_2, \dots, s_n)
$$는 토큰 단위의 조건부 확률로 계산된다. 즉, 문장 전체의 확률은 다음과 같다.

$$
p(s \mid x) = \prod_{i=1}^{n} p(s_i \mid s_{<i}, x)
$$

따라서 로그 확률은 다음과 같이 계산되며,

$$
\log p(s \mid x) = \sum_{i=1}^{n} \log p(s_i \mid s_{<i}, x)
$$

이를 통해 전체 문장의 확률 또는 로그 확률을 기반으로 불확실성을 추정한다. 다만, 문장이 길어질수록 곱셈된 확률이 작아지는 문제가 있어, 이를 보완하기 위해 문장 길이로 정규화한 로그 확률도 자주 사용된다.

$$
\frac{1}{n} \sum_{i=1}^{n} \log p(s_i \mid s_{<i}, x)
$$

이러한 방식은 단어 수가 많은 문장에 불리하게 작용하는 것을 막고, 문장 간의 확률 비교를 보다 공정하게 만든다. 하지만 이런 방식들은 모두 문장 단위의 토큰 시퀀스를 별개로 간주한다는 점에서 한계가 있다. 의미적으로 동일한 문장이라 하더라도 표현이 다르면 서로 다른 확률 항목으로 처리되어, 실제보다 더 높은 불확실성이 계산된다. 자연어에서 같은 의미를 가진 다양한 표현이 가능하다는 점을 고려하면, 이는 근본적인 한계이며 불확실성 측정을 왜곡시킬 수 있다.


## 의미 기반 불확실성 측정 (Semantic Entropy)

기존의 불확실성 측정 방식은 언어 모델이 생성한 문장을 각기 독립적인 시퀀스로 간주하여 확률을 계산한다. 하지만 자연어에서는 표현이 달라도 의미가 동일한 문장들이 다수 존재한다. 따라서 문장 자체가 아닌, **문장이 담고 있는 의미(semantic meaning)**를 기준으로 불확실성을 측정해야 한다는 필요성이 제기된다.

이를 위해 저자들은 Semantic Entropy라는 새로운 지표를 제안한다. 핵심 아이디어는 다음과 같다: 언어 모델이 생성한 여러 문장 중에서 같은 의미를 가진 문장들을 하나의 '의미 집합(semantic class)'으로 묶고, 이 의미 단위로 불확실성을 계산한다는 것이다.

구체적으로, 다음과 같은 3단계 절차를 따른다.
1. 샘플링: 주어진 질문이나 문맥 $$𝑥$$ 에 대해 언어 모델로부터 $$𝑀$$ 개의 문장 $$
s^{(1)},\ s^{(2)},\ \dots,\ s^{(M)}
$$을 샘플링한다.
2. 의미 클러스터링: 이들 문장을 서로 의미가 같은 것들끼리 묶는다. 두 문장이 서로를 **양방향으로 함의(entailment)**하면 같은 의미를 가진 것으로 판단한다.
3. 의미 기반 엔트로피 계산: 같은 의미 집합 내의 문장 확률들을 합산하여 의미 단위의 확률 분포를 만들고, 이에 대한 엔트로피를 계산한다.

이 과정을 수식으로 정리하면 다음과 같다. 먼저 의미 집합 $$𝑐 ∈ 𝐶$$ 의 확률은 다음과 같이 정의된다:

$$
p(c \mid x) = \sum_{s \in c} p(s \mid x)
$$
이제 전체 의미 공간 $$C$$에 대해 Semantic Entropy는 다음과 같이 계산된다.

$$
H_{\text{semantic}}(x) = - \sum_{c \in C} p(c \mid x) \log p(c \mid x)
$$
이때 실제 모델이 생성하는 문장들은 전체 의미 공간의 일부만 반영하기 때문에, 위 수식은 샘플링 기반 Monte Carlo 근사로 다음과 같이 표현된다:

$$
H_{\text{semantic}}(x) \approx - \frac{1}{|C|} \sum_{i=1}^{|C|} \log p(C_i \mid x)
$$
이 방식은 표현의 다양성을 허용하면서도 의미의 불확실성만을 측정할 수 있다는 점에서, 기존 방식보다 훨씬 더 직관적이고 신뢰할 수 있는 지표를 제공한다.





예를 들어, 아래와 같이 모델이 각각의 문장에 다음과 같은 확률을 부여했다고 생각해보자. 이때 의미는 같지만 표현이 다른 A와 B는 별개의 항목으로 처리되며, 전체 불확실성 계산에도 그대로 반영된다.

| 문장                                 | 확률 \( p(s \mid x) \) |
|--------------------------------------|:-----------------------:|
| A: "파리입니다."                      |           0.5           |
| B: "프랑스의 수도는 파리예요."         |           0.4           |
| C: "런던입니다."                      |           0.1           |

기존의 엔트로피 계산 방식은 이 세 문장을 모두 독립적으로 처리하여 다음과 같은 엔트로피를 계산한다.

$$H = - (0.5 * log 0.5 + 0.4 * log 0.4 + 0.1 * log 0.1) ≈ 0.94$$

이는 모델이 상당한 불확실성을 가진 것처럼 보이게 만든다. 그러나 실제로는 A와 B가 의미적으로 동일한 답변이라는 점을 고려하면, 이 둘을 하나의 의미 집합(semantic class)으로 묶을 수 있다. 이 경우 의미 기반 확률은 다음과 같이 재구성될 수 있다.

의미 집합 1 (“파리” 관련 답변들): 
- 의미 집합 1 ("파리" 관련): 0.5 + 0.4 = 0.9
- 의미 집합 2 ("런던"): 0.1

이제 의미 단위로 엔트로피를 계산하면:

$$H_semantic = - (0.9 * log 0.9 + 0.1 * log 0.1) ≈ 0.33$$

→ 의미를 기준으로 묶으면 실제 불확실성이 훨씬 낮게 측정됨.

즉, 표면적으로는 다양한 답변이 존재하는 것처럼 보였지만, 의미적 기준으로 보면 대부분의 확률이 하나의 정답에 몰려 있으며, 실제 불확실성은 훨씬 낮다는 것을 알 수 있다.