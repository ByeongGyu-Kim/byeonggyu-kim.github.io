---
title: "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation"
date: 2025-06-13 18:00:00 +0900
categories:
  - Paper-Review
tags:
  - Uncertainty Estimation
  - Semantic Uncertainty
  - ICLR 2023

description: 
toc: true
comments: false
cdn: 
image:
math: true
pin: false
mermaid: false
---

## 📄 논문 정보
[**"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation" (ICLR 2023)**](https://arxiv.org/abs/2302.09664)

## 🔍 연구 배경 및 문제의식
AI라는 개념이 우리에게 본격적으로 다가온 것은 아마도 알파고의 등장이 계기였을 것이다. 불과 몇 년 전만 해도 먼 미래의 기술처럼 느껴졌던 AI는 이제 ChatGPT나 Gemini 같은 언어 모델을 통해 우리의 일상 속 깊숙이 자리 잡았다. 우리는 자연스럽게 AI에게 질문을 던지고, 복잡한 글쓰기를 부탁하며, 번역이나 요약 같은 작업도 AI에 맡기곤 한다. 하지만 여기서 한 가지 중요한 의문, **"이 AI의 대답은 과연 얼마나 믿을 수 있을까?"**

예를 들어, “프랑스의 수도는 어디인가요?”라는 질문에 대해 언어 모델이 다음과 같은 세 개의 답변을 생성했다고 가정해보자.
- A: “파리입니다.”
- B: “프랑스의 수도는 파리예요.”
- C: “런던입니다.”

기존의 방식은 각 문장을 독립적으로 평가하며, 문장 B는 A와 동일한 의미를 가짐에도 불구하고 다른 표현이라는 이유로 별개의 확률 항목으로 간주한다. 이때 모델이 각 문장에 부여한 확률이 다음과 같다고 생각해보도록 하겠다.

| 문장                                 | 확률 $$p(s | x)$$ |
|--------------------------------------|---------------|
| A: "파리입니다."                      | 0.5           |
| B: "프랑스의 수도는 파리예요."         | 0.4           |
| C: "런던입니다."                      | 0.1           |

기존의 엔트로피 계산 방식은 이 세 문장을 모두 독립적으로 처리하여 다음과 같은 엔트로피를 계산한다:

$$H = - (0.5 * log 0.5 + 0.4 * log 0.4 + 0.1 * log 0.1) ≈ 0.94$$

이는 모델이 상당한 불확실성을 가진 것처럼 보이게 만든다. 그러나 실제로는 A와 B가 의미적으로 동일한 답변이라는 점을 고려하면, 이 둘을 하나의 의미 집합(semantic class)으로 묶을 수 있다. 이 경우 의미 기반 확률은 다음과 같이 재구성될 수 있다.

의미 집합 1 (“파리” 관련 답변들): 
- 의미 집합 1 ("파리" 관련): 0.5 + 0.4 = 0.9
- 의미 집합 2 ("런던"): 0.1

이제 의미 단위로 엔트로피를 계산하면:

$$H_semantic = - (0.9 * log 0.9 + 0.1 * log 0.1) ≈ 0.33$$

→ 의미를 기준으로 묶으면 실제 불확실성이 훨씬 낮게 측정됨.

즉, 표면적으로는 다양한 답변이 존재하는 것처럼 보였지만, 의미적 기준으로 보면 대부분의 확률이 하나의 정답에 몰려 있으며, 실제 불확실성은 훨씬 낮다는 것을 알 수 있다.

이처럼 의미 기반 엔트로피(Semantic Entropy)는 기존 방식에 비해 AI가 실제로 얼마나 확신을 가지고 있는지를 훨씬 더 정확하게 반영할 수 있다. 모델의 답변을 판단하는 데 있어 우리가 인간적으로 느끼는 “확실함”을 수치적으로 복원해주는 셈이다.
이 논문은 바로 그 지점에서 출발한다. 언어 모델이 생성하는 다양한 문장 표현들 속에서 ‘의미적 동치성’을 중심으로 불확실성을 다시 정의하자는 것이다. 저자들은 이를 위해 Semantic Entropy라는 새로운 지표를 제안하고, 기존의 엔트로피 기반 불확실성 측정법이 놓치고 있던 중요한 사실—“다르게 말해도 의미는 같을 수 있다”—을 수학적으로 반영하는 방법을 제시한다. 그리고 놀랍게도, 이 방법은 별도의 학습이나 모델 구조 변경 없이도 기존의 대형 언어 모델에 그대로 적용할 수 있다.

## 기존 불확실성 측정의 한계
그렇다면 우선기존의 불확실성은 어떤 방식으로 측정했는지 