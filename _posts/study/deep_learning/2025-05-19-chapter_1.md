---
title: "Deep learning Chapter 1 - The Deep Learning Revolution "
date: 2025-05-19 18:00:00 +0900
categories:
  - Deep Learning
tags:
  - Machine Learning
description: 
toc: true
comments: false
cdn: 
image:
math: true
pin: false
mermaid: false
---

본 글은 **"Deep Learning: Foundations and Concepts"** (저자: Christopher Bishop)의 1장, The Deep Learning Revolution 내용을 한국어로 정리한 것입니다.

딥러닝은 인공지능(AI) 분야에서 가장 혁신적이고 영향력 있는 기술 중 하나로, 최근 몇 년간 급격한 발전을 이루어냈다. 1장에서는 딥러닝의 역사, 발전 과정, 그리고 다양한 응용 분야에 대해 살펴볼 것이다.

## 🌍 1.1 딥러닝의 영향력 (The Impact of Deep Learning)
우리는 현재 딥러닝이 가능한 혁명적인 시대에 살고 있으며, 이는 다양한 분야에서 큰 변화를 가져오고 있다. 딥러닝은 특히 이미지 인식, 자연어 처리, 의료 진단 등 여러 분야에서 뛰어난 성능을 보여주고 있다.
우선 이러한 딥러닝이 어떤 분야에서 어떻게 활용되고 있는지 살펴보도록 하겠다.

### 🧪 1.1.1 의료 진단
![Desktop View](/assets/img/deeplearning/chap1_figure1.png)
_Figure 1: 첫 번째 행은 위험한 악성 흑색종, 두 번째 행은 양성 모반에 해당하는 피부 병변의 예시이며, 두 범주를 훈련받지 않은 눈으로 구분하는 것은 매우 어렵다._

피부암 진단, 특히 흑색종의 경우에는 조기 발견 시 치료가 가능하지만, 일반적인 시각으로는 양성과 악성을 구분하기 매우 어렵다.
딥러닝은 약 2,500만 개의 가중치를 학습하여 병변 이미지만으로 양성인지 악성인지 분류할 수 있도록 훈련되었다.
이 문제는 **지도학습(supervised learning)**에 해당하며, 각 입력을 두 개의 범주 중 하나로 분류하는 분류(classification) 문제로 볼 수 있다.
기존에는 사람이 직접 알고리즘을 설계하기 어려웠던 문제였으나, 딥러닝을 통해 이미지 기반 진단이 가능해졌다.

### 🧬 1.1.2 단백질 구조 예측
![Desktop View](/assets/img/deeplearning/chap1_figure2.png)
_Figure 2: 단백질 T1044/6VR4의 3차원 구조를 나타낸 그림이다. 초록색 구조는 X선 결정학을 통해 얻은 실제 구조이며, 겹쳐진 파란색 구조는 AlphaFold라는 딥러닝 모델이 예측한 결과를 보여준다._

단백질은 아미노산 서열로 구성되며, 이로부터 3차원 구조를 예측하는 문제는 생물학의 오랜 난제였으나, 딥러닝 모델인 AlphaFold는 이 문제를 해결함으로써, 기존의 실험적 방법(예: X선 결정학, 핵자기 공명 등)에 비해 훨씬 저렴하고 효율적으로 구조를 예측할 수 있게 하였다.
이 문제 역시 입력인 아미노산 서열과 3D 구조를 출력하는 구조인 지도학습 문제에 해당한다.

### 🎨 1.1.3 이미지 생성
![Desktop View](/assets/img/deeplearning/chap1_figure3.png)
_Figure 3: 비지도학습으로 학습된 딥 뉴럴 네트워크에 의해 생성된 합성 얼굴 이미지이다._

사람 얼굴 이미지를 생성하는 작업은 **비지도학습(unsupervised learning)** 의 대표적인 사례이다. 모델은 라벨이 없는 이미지들을 학습한 뒤, 그와 유사한 새로운 이미지를 생성할 수 있도록 학습된다.

이러한 모델은 **생성모델(generative model)**이라 불리며, 텍스트 프롬프트를 입력으로 받아 그 의미에 맞는 이미지를 생성하는 기능도 가능하다.

### 🧠 1.1.4 대형 언어 모델 (LLM)
자연어 처리 분야에서는 **자기회귀 언어 모델(autoregressive language model)**이 핵심적인 구조로 사용된다.

이러한 모델은 주어진 단어 시퀀스를 기반으로 다음 단어를 예측하고, 그 과정을 반복하여 문장을 생성한다.

이 방식은 **자기지도학습(self-supervised learning)**의 대표적인 예로, 별도의 라벨 없이도 대규모 텍스트 데이터로부터 입력과 출력을 구성할 수 있다.

예를 들어, GPT-4는 “무한히 많은 소수가 존재한다는 증명을 셰익스피어 희곡의 형식으로 작성하라”는 프롬프트에 대해 극본 형태로 응답할 수 있는 능력을 보인다.

---

## 🧪 1.2 튜토리얼 예제
기계학습의 핵심 개념과 용어는 단순한 예제를 통해 쉽게 설명할 수 있다. 여기서는 입력값에 따라 목표값을 예측하는 다항식 곡선 피팅(polynomial curve fitting) 문제를 통해 기초 개념을 설명한다.

### 📊 1.2.1 합성 데이터 (Synthetic Data)
입력 변수 $$x$$와 목표 변수 $$t$$는 실수 값을 가지며, $$N$$개의 훈련 데이터 $$(x_n, t_n)$$쌍으로 이루어진 데이터셋이 주어진다고 가정한다. 목표는 새로운 입력값 
𝑥
^
x
^
 에 대해 
𝑡
t를 예측하는 것이다. 이를 **일반화(generalization)**라고 한다.



\section*{1.2 튜토리얼 예제}

기계학습의 핵심 개념과 용어는 단순한 예제를 통해 쉽게 설명할 수 있다. 여기서는 입력값에 따라 목표값을 예측하는 다항식 곡선 피팅 문제를 통해 기초 개념을 설명한다.

\subsection*{1.2.1 합성 데이터 (Synthetic Data)}

입력 변수 $x$와 목표 변수 $t$는 실수 값을 가지며, $N$개의 훈련 데이터 $(x_n, t_n)$ 쌍으로 이루어진 데이터셋이 주어진다고 가정한다. 목표는 새로운 입력값 $\hat{x}$에 대해 $t$를 예측하는 것이다. 이를 \textbf{일반화}(generalization)라고 한다.

예제에서는 $\sin(2\pi x)$ 함수를 기반으로 $x$를 균등하게 샘플링한 뒤, 가우시안 노이즈를 추가하여 $t$를 생성한다. 이처럼 실제 데이터는 일정한 패턴을 가지되, 노이즈로 인해 완전히 일치하지 않음을 반영한다.

\subsection*{1.2.2 선형 모델 (Linear Models)}

데이터를 모델링하기 위해 다음과 같은 $M$차 다항식을 사용한다:

$$
y(x, \mathbf{w}) = \sum_{j=0}^{M} w_j x^j
$$

이 모델은 입력 $x$에 대해서는 비선형이지만, 계수 $\mathbf{w}$에 대해서는 선형이므로 \textbf{선형 모델}(linear model)이라 부른다.

\subsection*{1.2.3 오차 함수 (Error Function)}

모델을 학습하기 위해 오차 함수를 최소화해야 한다. 가장 단순한 방법은 \textbf{제곱 오차}(sum-of-squares error)를 사용하는 것이다:

$$
E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^{N} \left( y(x_n, \mathbf{w}) - t_n \right)^2
$$

이 함수는 예측값과 실제값의 차이 제곱을 합산하며, 오차가 작을수록 모델의 성능이 높다고 판단한다.

\subsection*{1.2.4 모델 복잡도 (Model Complexity)}

다항식의 차수 $M$은 모델 복잡도에 해당하며, 작은 $M$은 \textbf{과소적합}(underfitting), 너무 큰 $M$은 \textbf{과적합}(overfitting) 문제를 초래한다.

$M = 0, 1$의 경우 모델이 단순하여 정확도가 낮다. $M = 3$은 적절한 복잡도로 일반화 성능이 좋다. $M = 9$는 훈련 데이터에는 완벽히 맞지만 테스트 데이터에는 잘 맞지 않으며, 이는 전형적인 과적합이다.

성능은 \textbf{RMS 오차}로 평가할 수 있다:

$$
E_{\mathrm{RMS}} = \sqrt{ \frac{1}{N} \sum_{n=1}^{N} \left( y(x_n, \mathbf{w}) - t_n \right)^2 }
$$

\subsection*{1.2.5 정규화 (Regularization)}

과적합을 방지하기 위해 모델 복잡도를 제한하는 대신 \textbf{정규화}(regularization)를 적용할 수 있다. 이는 가중치의 크기에 패널티를 부여하는 방식이다:

$$
\tilde{E}(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^{N} \left( y(x_n, \mathbf{w}) - t_n \right)^2 + \frac{\lambda}{2} \|\mathbf{w}\|^2
$$

여기서 $\lambda$는 정규화 강도를 조절하는 하이퍼파라미터이며, 이 값이 클수록 가중치는 작아진다. 이는 신경망에서는 \textbf{weight decay}라고도 불린다.

\subsection*{1.2.6 모델 선택 (Model Selection)}

정규화 계수 $\lambda$나 다항식 차수 $M$은 \textbf{하이퍼파라미터}(hyperparameter)로, 훈련 과정에서는 고정되어 있다. 이를 적절히 선택하기 위해 \textbf{검증 데이터}(validation set)를 사용하거나, \textbf{교차 검증}(cross-validation)을 통해 모델 성능을 평가할 수 있다.

$S$-겹 교차 검증($S$-fold cross-validation)은 전체 데이터를 $S$개로 나누어 번갈아가며 검증을 수행한다. 데이터가 매우 적을 경우에는 \textbf{leave-one-out} 방식이 사용되기도 한다.

실제 기계학습에서는 데이터가 훨씬 크고, 입력 차원도 수백만 개에 이르며, 신경망 구조는 수십억 개의 파라미터를 포함할 수 있다. 이런 경우 오차 함수는 더 이상 해석적으로 풀 수 없고, 경사 하강법 등 반복적인 최적화 방법을 사용해야 한다.

🧠 1.3 머신러닝의 역사 (A Brief History of Machine Learning)
머신러닝은 다양한 접근 방식과 함께 오랜 역사를 가지고 있으며, 이 중에서도 신경망 기반 방법의 발전은 딥러닝의 핵심이자 실용적 성과가 뛰어난 접근법이다.

🔹 1.3.1 단층 신경망 (Single-layer Networks)
초기의 인공신경망 모델은 인간 뇌의 뉴런 구조에서 영감을 받았다. 뉴런은 다음과 같은 선형 조합을 통해 자극을 받고,

𝑎
=
∑
𝑖
=
1
𝑀
𝑤
𝑖
𝑥
𝑖
a= 
i=1
∑
M
​
 w 
i
​
 x 
i
​
 
비선형 활성화 함수를 거쳐 출력값을 계산한다:

𝑦
=
𝑓
(
𝑎
)
y=f(a)
이러한 모델의 대표적인 예는 퍼셉트론(perceptron)으로, 다음과 같은 계단 함수(step function)를 사용한다:

𝑓
(
𝑎
)
=
{
0
,
if 
𝑎
≤
0
1
,
if 
𝑎
>
0
f(a)= 
⎩
⎨
⎧
​
  
0,
1,
​
  
if a≤0
if a>0
​
 
퍼셉트론은 단층 구조만 학습이 가능하며, XOR 문제와 같이 선형 분리 불가능한 문제는 해결할 수 없다. 이 한계는 Minsky와 Papert(1969)에 의해 수학적으로 분석되었고, 이로 인해 1970–80년대에는 신경망에 대한 연구가 침체되었다.

🔹 1.3.2 역전파 알고리즘 (Backpropagation)
신경망 학습의 돌파구는 연속적이고 미분 가능한 활성화 함수를 사용하고, 오차 함수의 그래디언트를 계산해 파라미터를 업데이트하는 역전파 알고리즘을 통해 이루어졌다.

두 개 이상의 층을 가지는 다음 구조의 신경망이 등장하였다:

입력층 → 은닉층(hidden layer) → 출력층

각 유닛은 다음과 같이 계산된다:

𝑎
(
𝑙
)
=
∑
𝑗
𝑤
𝑗
(
𝑙
)
𝑥
𝑗
a 
(l)
 = 
j
∑
​
 w 
j
(l)
​
 x 
j
​
 
𝑦
(
𝑙
)
=
𝑓
(
𝑎
(
𝑙
)
)
y 
(l)
 =f(a 
(l)
 )
이러한 구조는 순전파 신경망(feed-forward neural network)이라 불리며, 학습은 다음과 같은 과정을 통해 이루어진다:

파라미터 초기화

순전파 계산 (forward pass)

오차 계산 및 역전파 (backward pass)

그래디언트를 이용한 파라미터 업데이트 (예: stochastic gradient descent)

이 방식은 1980년대 중반부터 본격적으로 사용되기 시작했으며, 기초 수학 이론(확률론, 통계학)에 기반을 두고 더욱 체계적으로 발전하였다.

🔹 1.3.3 딥러닝의 부상 (Deep Networks)
21세기 들어 여러 기술적 진보가 합쳐지면서, 딥 뉴럴 네트워크(deep neural networks)의 학습이 가능해졌고, 딥러닝(deep learning)이라는 새로운 장이 열렸다.

대표적인 요소는 다음과 같다:

모델 규모 확대: 수천만~수천억 개의 파라미터를 가진 모델 등장

데이터 확장: 대규모 이미지, 텍스트, 오디오 등의 데이터셋 활용

GPU 활용: 병렬처리가 가능한 GPU를 통한 빠른 연산

자동 미분 (autodiff): 미분 계산을 자동화하여 실험 효율성 증가

이러한 발전은 연산량 측면에서도 극적인 증가를 동반하였다:

1
 PFLOP/s-day
=
10
15
 FLOPs/s
×
1
 day
=
10
20
 operations
1 PFLOP/s-day=10 
15
  FLOPs/s×1 day=10 
20
  operations
이러한 추세는 Moore의 법칙을 넘어서는 수준이며, 최근 몇 년간 연산량은 매년 약 10배씩 증가하고 있다.

전이학습(transfer learning), 표현 학습(representation learning), 파운데이션 모델(foundation models) 등의 개념이 함께 발전하면서, 하나의 모델이 다양한 문제에 대응할 수 있는 유연성이 확보되고 있다.

또한 ResNet의 residual connection, 다양한 오픈소스 프레임워크, 논문 및 코드 공개 문화 등도 딥러닝의 빠른 성장에 중요한 역할을 하고 있다.