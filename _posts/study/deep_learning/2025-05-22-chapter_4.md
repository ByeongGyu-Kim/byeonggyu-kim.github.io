---
title: "Deep learning Chapter 4 - Single layer Networks: Regression "
date: 2025-05-22 18:00:00 +0900
categories:
  - Deep Learning
tags:
  - Machine Learning
description: 
toc: true
comments: false
cdn: 
image:
math: true
pin: false
mermaid: false
---

본 글은 **"Deep Learning: Foundations and Concepts"** (저자: Christopher Bishop)의 4장, Single layer Networks: Regression 내용을 한국어로 정리한 것입니다.

## 0. Regression이란?
**Regression**은 입력 $$x$$에 대해 연속적인 수치형 값 $$y$$를 예측하는 머신러닝 문제로 키에 따라 몸무게를 예측한다던지, 과거의 데이터에 기반하여 미래 주가를 예측하는 등의 문제들을 풀게 된다. 

$$
\hat{y} = f(x)
$$
여기서 $$f$$는 학습된 모델이며, $$\hat{y}$$는 예측값이다.

이러한 regression이란 단어는 1880년대 처음 유래되었는데, 생물학자 **Galton**은 부모와 자식의 키 사이의 관계를 연구를 진행했으며, 당연하게도 키 큰 부모의 자식은 평균보다 크지만 부모보다 크지 않고, 반대로 키 작은 부모의 자식은 평균보다 작지만 부모만큼 작지는 않다는 것을 발견하였다는 것이다. 이로써 자식의 키는 **평균으로 "회귀(regress)"**하는 경향이 있다고 분석하였으며 이러한 현상을 **“regression toward the mean”**이라 부르고 관계를 설명하는 식을 **"regression equation"**이라고 명명하게 되었다.

이러한 Regression은 Machine Learning 분야에서 주요한 task 중 하나이며 지금부터는 이에 대해 살펴보도록 하겠다.

## 1. Linear Regression
선형 회귀는 연속적인 목표값 $$t$$를 예측하기 위해 입력 벡터 $$\mathbf{x}$$에 기반하여 모델을 구성하게 되며 가장 단순한 형태를 생각해보게 되면 선형 결합을 이용하는 방법이다.

입력이 $$\mathbf{x} = (x_1, \dots, x_D)^T$$일 때, 선형 회귀 모델은 다음과 같이 나타낼 수 있으며, 이는 파라미터 $$\mathbf{w}$$에 대해 선형입니다. 하지만 입력 $$\mathbf{x}$$에도 선형이기 때문에, 복잡한 패턴을 포착하는 데 한계가 있습니다.

$$
y(\mathbf{x}, \mathbf{w}) = w_0 + w_1 x_1 + \dots + w_D x_D = \mathbf{w}^T \mathbf{x}
$$

### Basis Function 확장

선형 모델의 표현력을 높이기 위해, 입력에 비선형 변환을 적용한 basis function을 사용하게 되며, 이를 통해 비선형 관계도 포착할 수 있다.

$$
y(\mathbf{x}, \mathbf{w}) = \sum_{j=0}^{M-1} w_j \phi_j(\mathbf{x}) = \mathbf{w}^T \phi(\mathbf{x})
$$

여기서 $$\phi_0(\mathbf{x}) = 1$$로 정의하면 $$w_0$$는 bias로 


## 4.1.1 Basis Functions

- 선형 모델의 확장 → 비선형 변환 $\phi_j(x)$ 사용:
  $$
  y(\mathbf{x}, \mathbf{w}) = \sum_{j=0}^{M-1} w_j \phi_j(\mathbf{x}) = \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x})
  $$

- 예시 기저 함수들:
  - 다항식: $$\phi_j(x) = x^j$$
  - 가우시안: 
    $$
    \phi_j(x) = \exp\left( -\frac{(x - \mu_j)^2}{2s^2} \right)
    $$
  - 시그모이드:
    $$
    \phi_j(x) = \sigma\left( \frac{x - \mu_j}{s} \right), \quad \sigma(a) = \frac{1}{1 + e^{-a}}
    $$
  - tanh 함수:
    $$
    \tanh(a) = 2\sigma(2a) - 1
    $$

---

## 4.1.2 Likelihood Function

- 모델: 
  $$
  t = y(\mathbf{x}, \mathbf{w}) + \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \sigma^2)
  $$

- 조건부 확률:
  $$
  p(t \mid \mathbf{x}, \mathbf{w}, \sigma^2) = \mathcal{N}(t \mid y(\mathbf{x}, \mathbf{w}), \sigma^2)
  $$

- 전체 데이터에 대한 우도:
  $$
  p(\mathbf{t} \mid X, \mathbf{w}, \sigma^2) = \prod_{n=1}^N \mathcal{N}(t_n \mid \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x}_n), \sigma^2)
  $$

- 로그 우도:
  $$
  \log p = -\frac{N}{2} \log \sigma^2 - \frac{N}{2} \log(2\pi) - \frac{1}{\sigma^2} E_D(\mathbf{w})
  $$

- 오차 함수:
  $$
  E_D(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \left( t_n - \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x}_n) \right)^2
  $$

---

## 4.1.3 Maximum Likelihood

- 최대우도 해:
  $$
  \mathbf{w}_{ML} = \left( \Phi^T \Phi \right)^{-1} \Phi^T \mathbf{t}
  $$

- 분산 추정:
  $$
  \sigma^2_{ML} = \frac{1}{N} \sum_{n=1}^N \left( t_n - \mathbf{w}_{ML}^T \boldsymbol{\phi}(\mathbf{x}_n) \right)^2
  $$

---

## 4.1.4 Geometry of Least Squares

- 직교 투영 해:
  $$
  \mathbf{y} = \Phi \mathbf{w}_{ML}, \quad \mathbf{P} = \Phi \left( \Phi^T \Phi \right)^{-1} \Phi^T
  $$

- $\mathbf{P}$는 $\mathbf{t}$를 부분공간 $S$로 투영

---

## 4.1.5 Sequential Learning

- 확률적 경사 하강법 (SGD):
  $$
  \mathbf{w}^{(\tau+1)} = \mathbf{w}^{(\tau)} + \eta \left( t_n - \mathbf{w}^{(\tau)T} \phi_n \right) \phi_n
  $$

- LMS (Least-Mean-Squares) 알고리즘

---

## 4.1.6 Regularized Least Squares

- 정규화된 오차 함수:
  $$
  E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \left( t_n - \mathbf{w}^T \boldsymbol{\phi}(\mathbf{x}_n) \right)^2 + \frac{\lambda}{2} \mathbf{w}^T \mathbf{w}
  $$

- 해:
  $$
  \mathbf{w} = \left( \lambda I + \Phi^T \Phi \right)^{-1} \Phi^T \mathbf{t}
  $$

---

## 4.1.7 Multiple Outputs

- 출력 벡터: $$\mathbf{t} = (t_1, \dots, t_K)^T$$
- 모델:
  $$
  \mathbf{y}(x, W) = W^T \boldsymbol{\phi}(x)
  $$

- 최대우도 해:
  $$
  W_{ML} = \left( \Phi^T \Phi \right)^{-1} \Phi^T T
  $$

---

## 4.2 Decision Theory

- 예측 분포:
  $$
  p(t \mid x) = \mathcal{N}(t \mid y(x, \mathbf{w}_{ML}), \sigma^2_{ML})
  $$

- 기대 손실:
  $$
  \mathbb{E}[L] = \iint L(t, f(x)) p(x, t) \, dx \, dt
  $$

- 제곱 손실을 사용할 때:
  $$
  f^*(x) = \mathbb{E}[t \mid x]
  $$

- 분해:
  $$
  \mathbb{E}[L] = \int (f(x) - \mathbb{E}[t \mid x])^2 p(x) dx + \int \text{Var}[t \mid x] p(x) dx
  $$

- 일반적인 $L_q$ 손실:
  $$
  \mathbb{E}[L_q] = \iint |f(x) - t|^q p(x, t) dx dt
  $$

---

## 4.3 Bias–Variance Trade-off

- 기대 오차 분해:
  $$
  \mathbb{E}[L] = \text{Bias}^2 + \text{Variance} + \text{Noise}
  $$

- Bias:
  $$
  \text{Bias}^2 = \int \left( \mathbb{E}_{\mathcal{D}}[f(x; \mathcal{D})] - h(x) \right)^2 p(x) dx
  $$

- Variance:
  $$
  \text{Var} = \int \mathbb{E}_{\mathcal{D}} \left[ \left( f(x; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(x; \mathcal{D})] \right)^2 \right] p(x) dx
  $$

- Noise:
  $$
  \text{Noise} = \iint (h(x) - t)^2 p(x, t) dx dt
  $$

- 모델 복잡도 증가 시:
  $$
  \text{Bias} \downarrow, \quad \text{Variance} \uparrow
  $$

- 최적 정규화:
  $$
  \lambda^* = \arg \min_\lambda \left( \text{Bias}^2 + \text{Variance} \right)
  $$
